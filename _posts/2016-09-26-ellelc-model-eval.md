---
title: "模型性能评价指标"
author: "Elle Liu"
date: "26 September 2016"
layout: single
header:
  overlay_color: "#5e616c"
  overlay_image: unsplash-gallery-image-1.jpg
  padding: 9.5em
excerpt: '**常见指标介绍**'
comments: true
categories: [ML]
tags: [Statistics]
mathjax: true
highlight: false
description: "模型评价的常见指标介绍"
---

就分类模型而言，为了更好的评价数据集D上训练模型的优劣，我们将数据集D分为两部分，一部分为训练集S，一部分为测试集T。

## 样本划分

### 1. 留出法

步骤：
直接将数据集D分为两个互斥的集合，其中一部分作为训练集**S**，另一部分作为测试集**T**，有$$S \cup T=D，S \cap T= \Theta $$ 其中，测试集**T**评估的测试误差，是泛化误差的估计。

PS:

- 对**S**和**T**的划分要尽可能保持数据分布的一致性，如分类任务中要样本类别的比例一致（类似分层抽样）；
- S和T的划分存在多种方式，因此需要多次使用留出法以得到稳定性的估计结果。即对$D$使用多次随机划分（分层抽样），重复进行实验，评估后取平均值作为留出法的评估结果；

### 2. 交叉验证法

步骤： 

1）将数据集$$D$$划分为$$k$$个互斥的数据子集，每个子集$$D_i$$都具有数据一致性，然后用$$k-1$$个子集作为训练集$$S_i$$，剩下的子集作为测试集$$T_i$$,即可得到$k$次训练结果和测试，最终返回$$k$$次测试的均值，常用的有10折交叉验证；

2）对$$D$$进行多次划分，随机使用不同的划分重复$$p$$次。最终返回$$p$$次$$k$$折交叉验证结果的均值，常用的有10次10折交叉验证；

PS：

- 10次10折交叉验证≠100次留出法，但两者均进行了100次训练测试
-  留一法交叉验证：是指若D中有m个数据，则k=m，训练集为m-1，测试集为1。这样可以减少因为样本划分带来的误差（划分方式有且仅有一种），使评估结果更加准确，但计算开销巨大；

### 3. 自助法
        
避免因训练样本规模不同（减小）而导致的估计偏差

步骤：

1）数据集D有m个数据，则对D进行有放回抽样，抽取m次（每次抽一个），得到样本规模为m的数据集D；

2）由于进行有放回抽样，故D中存在被多次抽取的数据和未被抽到的数据。根据计算，原始数据中约有36.8%的数据始终未被抽中出现在D中。因此我们得到了规模不变仍未m个数据的数据集D，同时未出现在D中的数据成为测试集。

PS：

- 优点：对于数据量较小，难以有效划分训练/测试集时，Boosting方法有用，且可以从D中生成多个不同的训练集；
- D的数据分布与D不一致（有放回抽样），引入新的估计偏差，所以若数据量足够大，建议采用留出法或交叉验证法；

## 性能度量

### 1.错误率与准确率

 有m个数据，错分类样本个数为a，则：

$$ 错误率 = \frac{a}{m} $$

$$准确率 = (1-\frac{a}{m})*100% $$

### 2.查全率与查准率

<table>
    <tr>
        <th rowspan="2"> </th>
        <th></th>
        <th colspan="2">预测</th>
    </tr>
    <tr>
        <td></td>
        <td>正</td>
        <td>反</td>
    </tr>
    <tr>
        <td rowspan="2">真实</td>
        <td>正</td>
        <td>TP</td>
        <td>FN（假反例）</td>
    </tr>
    <tr>
        <td>反</td>
        <td>FP</td>
        <td>TN</td>
    </tr>
</table>

$$查准率(准确率): P=\frac{TP}{TP+FP}$$

$$查全率: R=\frac{TP}{TP+FN}$$

比较P-R常用统计量：

- BEP：查全率=查准率时二者的取值
- \\(F_1: \frac{1}{F_1}=\frac{1}{2}(\frac{1}{p}+\frac{1}{R})\\)
- \\(F_\beta: \frac{1}{F_1}=\frac{1}{1+\beta^2}(\frac{1}{p}+\frac{\beta^2}{R})\\)

其中，

若$$\beta>1$$，则R比P更重要（如逃犯识别系统）;
若$$\beta=1$$，则退化为$$F_1$$;
若$$\beta<1$$，则P比R更重要（如用户推荐系统）.

### 3. ROC 和 AUC

**ROC**

ROC横轴是假正例率FRP，纵轴是真正例率TRP，其中：

$$TRP=\frac{TP}{TP+FN}$$

$$FRP=\frac{FP}{FP+TN}$$

PS：

- ROC可用于判断模型优劣，越凸越好，越靠近y=x越不好；
- 比较两条交叉的ROC曲线时，给定一个x，比较对应y，越高越好；
- 由于ROC中TRP和FPR是直接计算分类错误的次数，因此对于分类错误代价非均等的情况，ROC曲线不能反应训练模型的期望总体代价，转用代价曲线；

**AUC**

AUC是ROC曲线下的面积，一般 $$\in$$ (0.5,1），较大的AUC代表模型较好。

